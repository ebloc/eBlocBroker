#AccountingStorageEnforce=0
#AccountingStorageHost=
#AccountingStoragePass=
#AccountingStoragePort=
AccountingStorageType=accounting_storage/slurmdbd
#AccountingStorageUser=
#AccountingStoreFlags=
#BatchStartTimeout=10
ClusterName=eblocbroker
#CompleteWait=0
# COMPUTE NODES
#DebugFlags=
#DefMemPerCPU=0
#DisableRootJobs=NO
#EnforcePartLimits=NO
#Epilog=
#EpilogMsgTime=2000
#EpilogSlurmctld=
#FirstJobId=1
#FrontEndName=slurmctl
#GetEnvTimeout=2
#GresTypes=
#GroupUpdateForce=0
#GroupUpdateTime=600
#HealthCheckInterval=0
#HealthCheckProgram=
InactiveLimit=0
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/linux
#JobCompHost=
#JobCompLoc=
#JobCompPass=
#JobCompPort=
JobCompType=jobcomp/none
#JobCompUser=
#JobContainerType=job_container/none
#JobFileAppend=0
# JOB PRIORITY
#JobRequeue=1
#JobSubmitPlugins=lua
#KillOnBadExit=0
KillWait=30
#LaunchType=launch/slurm
#Licenses=foo*4,bar
# LOGGING AND ACCOUNTING
MailProg=/var/ebloc-broker/slurm_mail_prog.sh
#MaxJobCount=10000
#MaxJobId=67043328
#MaxMemPerCPU=0
#MaxStepCount=40000
#MaxTasksPerNode=512
#MessageTimeout=10
MinJobAge=172800  # 48 h
MpiDefault=none
#MpiParams=ports=#-#
# NodeName=home NodeHostName=localhost CPUs=80 Sockets=2 CoresPerSocket=20 ThreadsPerCore=2 RealMemory=515896 State=UNKNOWN
#
# NodeName=home[1-2] NodeHostName=localhost NodeAddr=127.0.0.1 RealMemory=1000 CPUs=1
# PartitionName=debug Nodes=ALL Default=YES MaxTime=INFINITE State=UP MaxNodes=4

# NodeName=home[1-4] NodeHostName=home RealMemory=1000
# PartitionName=debug Nodes=ALL Default=YES MaxTime=INFINITE State=UP Shared=FORCE:1
# NodeName=c2 NodeAddr=127.0.0.1 RealMemory=1000
# NodeName=c3 NodeAddr=127.0.0.1 RealMemory=1000
# NodeName=c4 NodeAddr=127.0.0.1 RealMemory=1000
#OverTimeLimit=0
# PartitionName=debug Nodes=ALL Default=YES MaxTime=INFINITE State=UP Shared=FORCE:1 MaxNodes=1
# PartitionName=debug Nodes=c[3-4] Priority=50 DefMemPerCPU=500 Shared=NO MaxNodes=2 MaxTime=5-00:00:00 DefaultTime=5-00:00:00 State=UP
# PartitionName=normal Default=yes Nodes=c[1-2] Priority=50 DefMemPerCPU=500 Shared=NO MaxNodes=2 MaxTime=5-00:00:00 DefaultTime=5-00:00:00 State=UP
#
# PARTITIONS
#PluginDir=
#PlugStackConfig=
# POWER SAVE SUPPORT FOR IDLE NODES (optional)
#PriorityCalcPeriod=
#PriorityDecayHalfLife=
#PriorityFavorSmall=
#PriorityFlags=
#PriorityMaxAge=
PriorityType=priority/multifactor
#PriorityUsageResetPeriod=
#PriorityWeightAge=
#PriorityWeightFairshare=
#PriorityWeightJobSize=
#PriorityWeightPartition=
#PriorityWeightQOS=
#PrivateData=jobs
ProctrackType=proctrack/linuxproc
#Prolog=
#PrologFlags=
#PrologSlurmctld=
#PropagatePrioProcess=0
#PropagateResourceLimits=
#PropagateResourceLimitsExcept=
#RebootProgram=
#ResumeProgram=
#ResumeRate=
#ResumeTimeout=
#ResvOverRun=0
ReturnToService=1
#SchedulerTimeSlice=30
SchedulerType=sched/backfill
# SCHEDULING
SelectTypeParameters=CR_CPU_Memory
SelectType=select/cons_tres
SlurmctldDebug=debug
SlurmctldHost=leopar
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmctldPidFile=/var/run/slurm/slurmctld.pid
SlurmctldPort=6817
SlurmctldTimeout=120
SlurmdDebug=debug
SlurmdLogFile=/var/log/slurm/slurmd.%n.log
SlurmdPidFile=/var/run/slurmd.%n.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurmd.%n
SlurmdTimeout=300
#SlurmdUser=root
#SlurmSchedLogFile=
#SlurmSchedLogLevel=
SlurmUser=alper
#SrunEpilog=
#SrunProlog=
StateSaveLocation=/var/spool/slurmctld
#SuspendExcNodes=
#SuspendExcParts=
#SuspendProgram=
#SuspendRate=
#SuspendTime=
#SuspendTimeout=
SwitchType=switch/none
#TaskEpilog=
#TaskPlugin=task/none
#TaskProlog=
# TIMERS
#TmpFS=/tmp
#TopologyPlugin=topology/tree
#TrackWCKey=no
#TreeWidth=
#UnkillableStepProgram=
#UnkillableStepTimeout=60
#UsePAM=0
#VSizeFactor=0
Waittime=0

# slurmd -C ... RealMemory dogru girilimeli
# multiple core --------------------------------------------------------------------------------------
NodeName=leopar[1-4] NodeHostName=localhost Port=[6001-6004] NodeAddr=127.0.0.1 CPUs=1 RealMemory=1982
PartitionName=debug Default=yes Nodes=leopar[1-4]
# --------------------------------------------------------------------------------------------------

# single core --------------------------------------------------------------------------------------
NodeName=kama CPUs=1 Boards=1 SocketsPerBoard=1 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=976
PartitionName=debug Default=yes Nodes=kama
# --------------------------------------------------------------------------------------------------

# below old
# NodeName=leopar CPUs=4 Boards=1 SocketsPerBoard=2 CoresPerSocket=2 ThreadsPerCore=1 RealMemory=1982 NodeHostName=localhost
# PartitionName=debug Default=yes Nodes=leopar

# NodeName=leopar CPUs=1 Boards=1 SocketsPerBoard=1 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=976
# PartitionName=debug Default=yes

# NodeName=leopar NodeHostName=localhost CPUs=1 Sockets=2 CoresPerSocket=20 ThreadsPerCore=1 RealMemory=515896 State=UNKNOWN
# PartitionName=debug Default=yes